{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8494, 0.7672, 0.0182],\n",
      "        [0.2684, 0.1598, 0.5414],\n",
      "        [0.0158, 0.4437, 0.0012],\n",
      "        [0.5025, 0.5899, 0.3001],\n",
      "        [0.5113, 0.0821, 0.6465]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Optimizer\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os \n",
    "import json\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--print_every'], dest='print_every', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help='how often to print the loss.', metavar=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sgd import SGD_Simple\n",
    "from svrg import SVRG_k, SVRG_Snapshot\n",
    "from utils import MNIST_dataset, CIFAR10_dataset, MNIST_two_layers, MNIST_one_layer, CIFAR10_ConvNet, AverageCalculator, accuracy, plot_train_stats\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Train SVRG/SGD on MNIST data.\")\n",
    "parser.add_argument('--optimizer', type=str, default=\"SVRG\",\n",
    "                    help=\"optimizer.\")\n",
    "parser.add_argument('--nn_model', type=str, default=\"MNIST_one_layer\",\n",
    "                    help=\"neural network model.\")\n",
    "parser.add_argument('--dataset', type=str, default=\"MNIST\",\n",
    "                    help=\"neural network model.\")\n",
    "parser.add_argument('--n_epoch', type=int, default=100,\n",
    "                    help=\"number of training iterations.\")\n",
    "parser.add_argument('--lr', type=float, default=0.001,\n",
    "                    help=\"learning rate.\")\n",
    "parser.add_argument('--batch_size', type=int, default=64,\n",
    "                    help=\"batch size.\")\n",
    "parser.add_argument('--weight_decay', type=float, default=0.0001,\n",
    "                    help=\"regularization strength.\")\n",
    "parser.add_argument('--exp_name', type=str, default=\"\",\n",
    "                    help=\"name of the experiment.\")\n",
    "parser.add_argument('--print_every', type=int, default=1,\n",
    "                    help=\"how often to print the loss.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = \"outputs\"\n",
    "BATCH_SIZE_LARGE = 256  # for testing and the full-batch outer train loop\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "print(\"Using device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_SGD(model, optimizer, train_loader, loss_fn, flatten_img=True):\n",
    "    model.train()\n",
    "    loss = AverageCalculator()\n",
    "    acc = AverageCalculator()\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        if flatten_img:\n",
    "            images = images.view(images.shape[0], -1)\n",
    "        yhat = model(images)\n",
    "        labels = labels.to(device)\n",
    "        loss_iter = loss_fn(yhat, labels)\n",
    "\n",
    "        # optimization \n",
    "        optimizer.zero_grad()\n",
    "        loss_iter.backward()    \n",
    "        optimizer.step()\n",
    "\n",
    "        # logging \n",
    "        acc_iter = accuracy(yhat, labels)\n",
    "        loss.update(loss_iter.data.item())\n",
    "        acc.update(acc_iter)\n",
    "    \n",
    "    return loss.avg, acc.avg\n",
    "\n",
    "def train_epoch_SVRG(model_k, model_snapshot, optimizer_k, optimizer_snapshot, train_loader, loss_fn, flatten_img=True):\n",
    "    model_k.train()\n",
    "    model_snapshot.train()\n",
    "    loss = AverageCalculator()\n",
    "    acc = AverageCalculator()\n",
    "\n",
    "    # calculate the mean gradient\n",
    "    optimizer_snapshot.zero_grad()  # zero_grad outside for loop, accumulate gradient inside\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        if flatten_img:\n",
    "            images = images.view(images.shape[0], -1)\n",
    "        yhat = model_snapshot(images)\n",
    "        labels = labels.to(device)\n",
    "        snapshot_loss = loss_fn(yhat, labels) / len(train_loader)\n",
    "        snapshot_loss.backward()\n",
    "\n",
    "    # pass the current paramesters of optimizer_0 to optimizer_k \n",
    "    u = optimizer_snapshot.get_param_groups()\n",
    "    optimizer_k.set_u(u)\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        if flatten_img:\n",
    "            images = images.view(images.shape[0], -1)\n",
    "        yhat = model_k(images)\n",
    "        labels = labels.to(device)\n",
    "        loss_iter = loss_fn(yhat, labels)\n",
    "\n",
    "        # optimization \n",
    "        optimizer_k.zero_grad()\n",
    "        loss_iter.backward()    \n",
    "\n",
    "        yhat2 = model_snapshot(images)\n",
    "        loss2 = loss_fn(yhat2, labels)\n",
    "\n",
    "        optimizer_snapshot.zero_grad()\n",
    "        loss2.backward()\n",
    "\n",
    "        optimizer_k.step(optimizer_snapshot.get_param_groups())\n",
    "\n",
    "        # logging \n",
    "        acc_iter = accuracy(yhat, labels)\n",
    "        loss.update(loss_iter.data.item())\n",
    "        acc.update(acc_iter)\n",
    "    \n",
    "    # update the snapshot \n",
    "    optimizer_snapshot.set_param_groups(optimizer_k.get_param_groups())\n",
    "    \n",
    "    return loss.avg, acc.avg\n",
    "\n",
    "\n",
    "def validate_epoch(model, val_loader, loss_fn):\n",
    "    \"\"\"One epoch of validation\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    loss = AverageCalculator()\n",
    "    acc = AverageCalculator()\n",
    "\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        if flatten_img:\n",
    "            images = images.view(images.shape[0], -1)\n",
    "        yhat = model(images)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # logging \n",
    "        loss_iter = loss_fn(yhat, labels)\n",
    "        acc_iter = accuracy(yhat, labels)\n",
    "        loss.update(loss_iter.data.item())\n",
    "        acc.update(acc_iter)\n",
    "    \n",
    "    return loss.avg, acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer': 'SVRG', 'nn_model': 'MNIST_one_layer', 'dataset': 'MNIST', 'n_epoch': 100, 'lr': 0.001, 'batch_size': 64, 'weight_decay': 0.0001, 'exp_name': '', 'print_every': 1}\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784f8ded4b4743c9b17de5903fc12eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673a3ce5963a44e3a8ea18314fd240b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77ef8287a404ca2b5b7406f8cdf582a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b657384bd8d4060a12f557d6722ed6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/MNIST/raw\n",
      "Processing...\n",
      "Done!\n",
      "Using optimizer: SVRG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train loss: 1.8697, train acc: 0.5297, val loss: 1.4592, val acc: 0.6908, time: 17.73\n",
      "epoch: 1, train loss: 1.1871, train acc: 0.7581, val loss: 0.9559, val acc: 0.8009, time: 18.33\n",
      "epoch: 2, train loss: 0.8416, train acc: 0.8183, val loss: 0.7152, val acc: 0.8388, time: 18.41\n",
      "epoch: 3, train loss: 0.6738, train acc: 0.8443, val loss: 0.5959, val acc: 0.8554, time: 18.46\n",
      "epoch: 4, train loss: 0.5804, train acc: 0.8579, val loss: 0.5261, val acc: 0.8710, time: 17.56\n",
      "\n",
      "epoch: 5, train loss: 0.5216, train acc: 0.8675, val loss: 0.4769, val acc: 0.8767, time: 17.47\n",
      "epoch: 6, train loss: 0.4816, train acc: 0.8745, val loss: 0.4437, val acc: 0.8844, time: 17.97\n",
      "epoch: 7, train loss: 0.4531, train acc: 0.8791, val loss: 0.4165, val acc: 0.8891, time: 18.60\n",
      "epoch: 8, train loss: 0.4313, train acc: 0.8828, val loss: 0.4094, val acc: 0.8894, time: 18.41\n",
      "epoch: 9, train loss: 0.4143, train acc: 0.8864, val loss: 0.3901, val acc: 0.8924, time: 18.02\n",
      "\n",
      "epoch: 10, train loss: 0.4006, train acc: 0.8890, val loss: 0.3774, val acc: 0.8936, time: 18.56\n",
      "epoch: 11, train loss: 0.3892, train acc: 0.8913, val loss: 0.3668, val acc: 0.8986, time: 19.29\n",
      "epoch: 12, train loss: 0.3797, train acc: 0.8930, val loss: 0.3639, val acc: 0.8972, time: 20.05\n",
      "epoch: 13, train loss: 0.3714, train acc: 0.8949, val loss: 0.3466, val acc: 0.9027, time: 18.49\n",
      "epoch: 14, train loss: 0.3643, train acc: 0.8964, val loss: 0.3403, val acc: 0.9046, time: 18.30\n",
      "epoch: 15, train loss: 0.3578, train acc: 0.8979, val loss: 0.3346, val acc: 0.9041, time: 18.69\n",
      "epoch: 16, train loss: 0.3523, train acc: 0.8992, val loss: 0.3319, val acc: 0.9036, time: 18.48\n",
      "epoch: 17, train loss: 0.3472, train acc: 0.9007, val loss: 0.3310, val acc: 0.9033, time: 18.41\n",
      "epoch: 18, train loss: 0.3426, train acc: 0.9020, val loss: 0.3229, val acc: 0.9071, time: 18.03\n",
      "epoch: 19, train loss: 0.3384, train acc: 0.9032, val loss: 0.3184, val acc: 0.9096, time: 17.85\n",
      "epoch: 20, train loss: 0.3344, train acc: 0.9042, val loss: 0.3248, val acc: 0.9062, time: 17.95\n",
      "epoch: 21, train loss: 0.3308, train acc: 0.9051, val loss: 0.3266, val acc: 0.9058, time: 18.27\n",
      "epoch: 22, train loss: 0.3274, train acc: 0.9058, val loss: 0.3110, val acc: 0.9120, time: 18.01\n",
      "epoch: 23, train loss: 0.3245, train acc: 0.9067, val loss: 0.3146, val acc: 0.9073, time: 17.60\n",
      "epoch: 24, train loss: 0.3214, train acc: 0.9073, val loss: 0.3059, val acc: 0.9125, time: 18.11\n",
      "epoch: 25, train loss: 0.3186, train acc: 0.9083, val loss: 0.3008, val acc: 0.9132, time: 17.73\n",
      "epoch: 26, train loss: 0.3158, train acc: 0.9091, val loss: 0.3050, val acc: 0.9139, time: 17.69\n",
      "epoch: 27, train loss: 0.3134, train acc: 0.9099, val loss: 0.2960, val acc: 0.9157, time: 17.88\n",
      "epoch: 28, train loss: 0.3107, train acc: 0.9105, val loss: 0.2933, val acc: 0.9159, time: 18.35\n",
      "epoch: 29, train loss: 0.3085, train acc: 0.9110, val loss: 0.2929, val acc: 0.9162, time: 18.51\n",
      "epoch: 30, train loss: 0.3061, train acc: 0.9117, val loss: 0.2892, val acc: 0.9171, time: 17.75\n",
      "epoch: 31, train loss: 0.3041, train acc: 0.9124, val loss: 0.2948, val acc: 0.9150, time: 17.83\n",
      "epoch: 32, train loss: 0.3019, train acc: 0.9132, val loss: 0.2868, val acc: 0.9175, time: 19.21\n",
      "epoch: 33, train loss: 0.2998, train acc: 0.9139, val loss: 0.2856, val acc: 0.9196, time: 18.27\n",
      "epoch: 34, train loss: 0.2976, train acc: 0.9146, val loss: 0.2904, val acc: 0.9174, time: 17.90\n",
      "epoch: 35, train loss: 0.2955, train acc: 0.9152, val loss: 0.2867, val acc: 0.9179, time: 18.28\n",
      "epoch: 36, train loss: 0.2936, train acc: 0.9159, val loss: 0.2783, val acc: 0.9211, time: 21.14\n",
      "epoch: 37, train loss: 0.2916, train acc: 0.9164, val loss: 0.2875, val acc: 0.9185, time: 20.17\n",
      "epoch: 38, train loss: 0.2898, train acc: 0.9167, val loss: 0.2784, val acc: 0.9202, time: 19.98\n",
      "epoch: 39, train loss: 0.2878, train acc: 0.9172, val loss: 0.2767, val acc: 0.9223, time: 18.26\n",
      "epoch: 40, train loss: 0.2860, train acc: 0.9178, val loss: 0.2737, val acc: 0.9229, time: 17.74\n",
      "epoch: 41, train loss: 0.2842, train acc: 0.9184, val loss: 0.2727, val acc: 0.9223, time: 17.91\n",
      "epoch: 42, train loss: 0.2824, train acc: 0.9189, val loss: 0.2718, val acc: 0.9230, time: 17.81\n",
      "epoch: 43, train loss: 0.2807, train acc: 0.9194, val loss: 0.2683, val acc: 0.9248, time: 17.70\n",
      "epoch: 44, train loss: 0.2788, train acc: 0.9201, val loss: 0.2718, val acc: 0.9235, time: 17.84\n",
      "epoch: 45, train loss: 0.2771, train acc: 0.9207, val loss: 0.2723, val acc: 0.9225, time: 17.69\n",
      "epoch: 46, train loss: 0.2754, train acc: 0.9211, val loss: 0.2653, val acc: 0.9261, time: 17.53\n",
      "epoch: 47, train loss: 0.2738, train acc: 0.9215, val loss: 0.2633, val acc: 0.9264, time: 18.18\n",
      "epoch: 48, train loss: 0.2720, train acc: 0.9220, val loss: 0.2672, val acc: 0.9236, time: 18.68\n",
      "epoch: 49, train loss: 0.2703, train acc: 0.9225, val loss: 0.2634, val acc: 0.9238, time: 17.91\n",
      "epoch: 50, train loss: 0.2688, train acc: 0.9230, val loss: 0.2740, val acc: 0.9233, time: 17.84\n",
      "epoch: 51, train loss: 0.2671, train acc: 0.9237, val loss: 0.2605, val acc: 0.9267, time: 17.75\n",
      "epoch: 52, train loss: 0.2654, train acc: 0.9243, val loss: 0.2560, val acc: 0.9290, time: 17.97\n",
      "epoch: 53, train loss: 0.2637, train acc: 0.9249, val loss: 0.2556, val acc: 0.9295, time: 18.05\n",
      "epoch: 54, train loss: 0.2622, train acc: 0.9255, val loss: 0.2635, val acc: 0.9287, time: 18.23\n",
      "epoch: 55, train loss: 0.2606, train acc: 0.9259, val loss: 0.2529, val acc: 0.9288, time: 17.59\n",
      "epoch: 56, train loss: 0.2589, train acc: 0.9265, val loss: 0.2537, val acc: 0.9299, time: 17.68\n",
      "epoch: 57, train loss: 0.2575, train acc: 0.9269, val loss: 0.2507, val acc: 0.9300, time: 17.90\n",
      "epoch: 58, train loss: 0.2559, train acc: 0.9274, val loss: 0.2485, val acc: 0.9318, time: 18.39\n",
      "epoch: 59, train loss: 0.2542, train acc: 0.9278, val loss: 0.2578, val acc: 0.9278, time: 18.37\n",
      "epoch: 60, train loss: 0.2527, train acc: 0.9283, val loss: 0.2534, val acc: 0.9313, time: 18.23\n",
      "epoch: 61, train loss: 0.2513, train acc: 0.9286, val loss: 0.2443, val acc: 0.9330, time: 18.07\n",
      "epoch: 62, train loss: 0.2497, train acc: 0.9291, val loss: 0.2507, val acc: 0.9318, time: 18.10\n",
      "epoch: 63, train loss: 0.2483, train acc: 0.9295, val loss: 0.2426, val acc: 0.9318, time: 17.66\n",
      "epoch: 64, train loss: 0.2467, train acc: 0.9301, val loss: 0.2431, val acc: 0.9308, time: 18.74\n",
      "epoch: 65, train loss: 0.2453, train acc: 0.9305, val loss: 0.2386, val acc: 0.9339, time: 17.49\n",
      "epoch: 66, train loss: 0.2439, train acc: 0.9309, val loss: 0.2383, val acc: 0.9343, time: 17.96\n",
      "epoch: 67, train loss: 0.2422, train acc: 0.9315, val loss: 0.2366, val acc: 0.9343, time: 18.16\n",
      "epoch: 68, train loss: 0.2407, train acc: 0.9321, val loss: 0.2370, val acc: 0.9333, time: 17.80\n",
      "epoch: 69, train loss: 0.2392, train acc: 0.9326, val loss: 0.2331, val acc: 0.9351, time: 17.66\n",
      "epoch: 70, train loss: 0.2378, train acc: 0.9330, val loss: 0.2347, val acc: 0.9338, time: 18.17\n",
      "epoch: 71, train loss: 0.2365, train acc: 0.9334, val loss: 0.2392, val acc: 0.9325, time: 18.48\n",
      "epoch: 72, train loss: 0.2350, train acc: 0.9339, val loss: 0.2303, val acc: 0.9356, time: 18.33\n",
      "epoch: 73, train loss: 0.2336, train acc: 0.9343, val loss: 0.2328, val acc: 0.9328, time: 18.36\n",
      "epoch: 74, train loss: 0.2322, train acc: 0.9349, val loss: 0.2315, val acc: 0.9348, time: 17.82\n",
      "epoch: 75, train loss: 0.2308, train acc: 0.9354, val loss: 0.2253, val acc: 0.9363, time: 18.62\n",
      "epoch: 76, train loss: 0.2294, train acc: 0.9358, val loss: 0.2377, val acc: 0.9337, time: 18.14\n",
      "epoch: 77, train loss: 0.2281, train acc: 0.9362, val loss: 0.2255, val acc: 0.9354, time: 17.55\n",
      "epoch: 78, train loss: 0.2268, train acc: 0.9368, val loss: 0.2315, val acc: 0.9332, time: 17.41\n",
      "epoch: 79, train loss: 0.2253, train acc: 0.9372, val loss: 0.2284, val acc: 0.9334, time: 17.48\n",
      "epoch: 80, train loss: 0.2240, train acc: 0.9375, val loss: 0.2203, val acc: 0.9381, time: 17.50\n",
      "epoch: 81, train loss: 0.2228, train acc: 0.9378, val loss: 0.2246, val acc: 0.9370, time: 17.49\n",
      "epoch: 82, train loss: 0.2216, train acc: 0.9380, val loss: 0.2334, val acc: 0.9354, time: 17.53\n",
      "epoch: 83, train loss: 0.2201, train acc: 0.9384, val loss: 0.2217, val acc: 0.9355, time: 17.50\n",
      "epoch: 84, train loss: 0.2189, train acc: 0.9387, val loss: 0.2179, val acc: 0.9359, time: 17.43\n",
      "epoch: 85, train loss: 0.2177, train acc: 0.9391, val loss: 0.2244, val acc: 0.9362, time: 17.46\n",
      "epoch: 86, train loss: 0.2164, train acc: 0.9394, val loss: 0.2133, val acc: 0.9396, time: 17.46\n",
      "epoch: 87, train loss: 0.2153, train acc: 0.9400, val loss: 0.2161, val acc: 0.9372, time: 17.40\n",
      "epoch: 88, train loss: 0.2140, train acc: 0.9404, val loss: 0.2119, val acc: 0.9390, time: 17.45\n",
      "epoch: 89, train loss: 0.2128, train acc: 0.9405, val loss: 0.2111, val acc: 0.9410, time: 17.44\n",
      "epoch: 90, train loss: 0.2116, train acc: 0.9409, val loss: 0.2123, val acc: 0.9385, time: 17.56\n",
      "epoch: 91, train loss: 0.2104, train acc: 0.9414, val loss: 0.2103, val acc: 0.9400, time: 17.39\n",
      "epoch: 92, train loss: 0.2094, train acc: 0.9416, val loss: 0.2064, val acc: 0.9418, time: 17.41\n",
      "epoch: 93, train loss: 0.2081, train acc: 0.9420, val loss: 0.2054, val acc: 0.9421, time: 17.48\n",
      "epoch: 94, train loss: 0.2071, train acc: 0.9423, val loss: 0.2047, val acc: 0.9422, time: 17.44\n",
      "epoch: 95, train loss: 0.2059, train acc: 0.9426, val loss: 0.2031, val acc: 0.9425, time: 17.62\n",
      "epoch: 96, train loss: 0.2048, train acc: 0.9429, val loss: 0.2039, val acc: 0.9427, time: 17.52\n",
      "epoch: 97, train loss: 0.2037, train acc: 0.9431, val loss: 0.2023, val acc: 0.9430, time: 17.42\n",
      "epoch: 98, train loss: 0.2027, train acc: 0.9434, val loss: 0.2023, val acc: 0.9417, time: 17.46\n",
      "epoch: 99, train loss: 0.2015, train acc: 0.9438, val loss: 0.2023, val acc: 0.9420, time: 17.43\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    args, unknown = parser.parse_known_args()                     # The line was args = parser.parse_known_args()\n",
    "    args_dict = vars(args)\n",
    "\n",
    "    if not args.optimizer in ['SGD', 'SVRG']:\n",
    "        raise ValueError(\"--optimizer must be 'SGD' or 'SVRG'.\")\n",
    "    print(args_dict)\n",
    "\n",
    "    # load the data\n",
    "    if args.dataset == \"MNIST\":\n",
    "        train_set, val_set = MNIST_dataset()\n",
    "        flatten_img = True\n",
    "    elif args.dataset == \"CIFAR10\":\n",
    "        train_set, val_set = CIFAR10_dataset() \n",
    "        flatten_img = False\n",
    "    else:\n",
    "        raise ValueError(\"Unknown dataset\")\n",
    "    \n",
    "    train_loader = DataLoader(train_set, batch_size=args.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=BATCH_SIZE_LARGE, shuffle=True)\n",
    "\n",
    "    if args.nn_model == \"MNIST_one_layer\":\n",
    "        NN_model = MNIST_one_layer  # function name \n",
    "    elif args.nn_model == \"MNIST_two_layers\":\n",
    "        NN_model = MNIST_two_layers\n",
    "    elif args.nn_model == \"CIFAR10_convnet\":\n",
    "        NN_model = CIFAR10_ConvNet\n",
    "    else:\n",
    "        raise ValueError(\"Unknown nn_model.\")\n",
    "\n",
    "    model = NN_model().to(device)\n",
    "    if args.optimizer == 'SVRG':\n",
    "        model_snapshot = NN_model().to(device)\n",
    "\n",
    "    lr = args.lr  # learning rate\n",
    "    n_epoch = args.n_epoch  # the number of epochs\n",
    "\n",
    "    loss_fn = nn.NLLLoss()  # The loss function \n",
    "    if args.nn_model == \"CIFAR10_convnet\":\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # the optimizer \n",
    "    if args.optimizer == \"SGD\":\n",
    "        optimizer = SGD_Simple(model.parameters(), lr=lr, weight_decay=args.weight_decay)\n",
    "    elif args.optimizer == \"SVRG\":\n",
    "        optimizer = SVRG_k(model.parameters(), lr=lr, weight_decay=args.weight_decay)\n",
    "        optimizer_snapshot = SVRG_Snapshot(model_snapshot.parameters())\n",
    "\n",
    "\n",
    "    # output folder \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    model_name = timestamp + \"_\" + args.optimizer + \"_\" + args.nn_model\n",
    "    if args.exp_name != \"\":\n",
    "        model_name = args.exp_name + '_' + model_name\n",
    "    log_dir = os.path.join(OUTPUT_DIR, model_name)\n",
    "    if not os.path.isdir(OUTPUT_DIR):\n",
    "        os.mkdir(OUTPUT_DIR)\n",
    "    if not os.path.isdir(log_dir):\n",
    "        os.mkdir(log_dir)\n",
    "    with open(os.path.join(log_dir, \"args.json\"), \"w\") as f:\n",
    "        json.dump(args_dict, f)\n",
    "\n",
    "    # store training stats\n",
    "    train_loss_all, val_loss_all = [], []\n",
    "    train_acc_all, val_acc_all = [], []\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        t0 = time.time()\n",
    "\n",
    "        # training \n",
    "        if args.optimizer == \"SGD\":\n",
    "            train_loss, train_acc = train_epoch_SGD(model, optimizer, train_loader, loss_fn, flatten_img=flatten_img)\n",
    "        elif args.optimizer == \"SVRG\":\n",
    "            train_loss, train_acc = train_epoch_SVRG(model, model_snapshot, optimizer, optimizer_snapshot, train_loader, loss_fn, flatten_img=flatten_img)\n",
    "        \n",
    "        # validation \n",
    "        val_loss, val_acc = validate_epoch(model, val_loader, loss_fn)\n",
    "        \n",
    "        train_loss_all.append(train_loss)  # averaged loss for the current epoch \n",
    "        train_acc_all.append(train_acc)\n",
    "        val_loss_all.append(val_loss)  \n",
    "        val_acc_all.append(val_acc)\n",
    "        \n",
    "        fmt_str = \"epoch: {}, train loss: {:.4f}, train acc: {:.4f}, val loss: {:.4f}, val acc: {:.4f}, time: {:.2f}\"\n",
    "\n",
    "        if epoch % args.print_every == 0:\n",
    "            print(fmt_str.format(epoch, train_loss, train_acc, val_loss, val_acc, time.time() - t0))\n",
    "\n",
    "        # save data and plot \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            np.savez(os.path.join(log_dir, 'train_stats.npz'), \n",
    "                train_loss=np.array(train_loss_all), train_acc=np.array(train_acc_all),\n",
    "                val_loss=np.array(val_loss_all), val_acc=np.array(val_acc_all))\n",
    "            plot_train_stats(train_loss_all, val_loss_all, train_acc_all, val_acc_all, log_dir, acc_low=0.9)\n",
    "    # done\n",
    "    open(os.path.join(log_dir, 'done'), 'a').close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
